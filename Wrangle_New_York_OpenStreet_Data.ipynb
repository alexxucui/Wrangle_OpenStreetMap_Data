{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Wrangle New York OpenStreet Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tag names and counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_tags(filename):\n",
    "    tags = {}\n",
    "    for event, element in ET.iterparse(filename):\n",
    "        if element.tag not in tags.keys():\n",
    "            tags[element.tag] = 1\n",
    "        else:\n",
    "            tags[element.tag] += 1\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'member': 28,\n",
      " 'nd': 14329,\n",
      " 'node': 11447,\n",
      " 'osm': 1,\n",
      " 'relation': 9,\n",
      " 'tag': 9721,\n",
      " 'way': 1794}\n"
     ]
    }
   ],
   "source": [
    "tags = count_tags('newyork_sample.osm')\n",
    "pprint.pprint(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Tags\n",
    "\n",
    "We first check the \"k\" value for each tag and see if there are any potential problems. I proposed 3 regular expressions to check for certain patterns in the \"k\" value.\n",
    "- \"lower\", for tags that contain only lowercase letters and are valid\n",
    "- \"lower_colon\", for otherwise valid tags with a colon in their names\n",
    "- \"problemchars\", for tags with problematic characters\n",
    "- \"other\", for other tags that do not fall into the other three categories\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def key_type(element, keys):\n",
    "    if element.tag == \"tag\":\n",
    "\n",
    "        k = element.get(\"k\")\n",
    "\n",
    "        if re.search(lower,k):\n",
    "            keys['lower'] += 1\n",
    "        elif re.search(lower_colon,k):\n",
    "            keys['lower_colon'] += 1\n",
    "        elif re.search(problemchars,k):\n",
    "            keys['problemchars'] += 1\n",
    "        else:\n",
    "            keys['other'] +=1\n",
    "    \n",
    "    return keys\n",
    "\n",
    "def process_map(filename):\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = key_type(element, keys)\n",
    "        \n",
    "    return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': 3760, 'lower_colon': 5835, 'other': 105, 'problemchars': 21}\n"
     ]
    }
   ],
   "source": [
    "keys = process_map('newyork_sample.osm')\n",
    "pprint.pprint(keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Find unique users\n",
    "Find out how many unique users have contributed to the map in the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_users(filename):\n",
    "    users = set()\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        if element.get(\"uid\"):\n",
    "            users.add(element.attrib[\"uid\"])\n",
    "    return users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users = get_users('newyork_sample.osm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "433"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audit street names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Look for street name pattern\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "# Some expected comman street names\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \n",
    "            \"Drive\", \"Court\", \"Place\", \n",
    "            \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Group all the street names not expected\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check if it is a street name\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def audit(filename):\n",
    "    \n",
    "    # specify the encoding for python3\n",
    "    osm_file = open(filename, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return street_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "street_types = audit('newyork_sample.osm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<type 'set'>, {'West': set(['Henry Hudson Parkway West']), 'Way': set(['Ilyssa Way']), 'Circle': set(['Covington Circle']), 'East': set(['Van Cortlandt Avenue East']), 'Highway': set(['Kings Highway', 'New Highway']), 'North': set(['Grand Central Parkway Sr North', 'Horace Harding Expressway Service Road North']), 'Park': set(['Harding Park']), 'Loop': set(['Leewood Loop', 'Hart Loop']), 'Path': set(['Carlls Path', 'Carlls Straight Path']), 'A': set(['Avenue A']), 'B': set(['Avenue B']), 'I': set(['Avenue I']), 'H': set(['Avenue H']), 'K': set(['Avenue K']), 'J': set(['Avenue J']), 'L': set(['Avenue L']), 'P': set(['Avenue P']), 'Green': set(['Dover Green']), 'T': set(['Avenue T']), 'W': set(['Somerset Road W']), 'Turnpike': set(['Union Turnpike', 'Hempstead Turnpike']), 'Z': set(['Avenue Z']), 'South': set(['Juniper Boulevard South']), 'Cir': set(['Winnecomac Cir']), 'Ballfields': set(['John Golden Ballfields']), 'Terrace': set(['Susan Terrace']), 'Slip': set(['Catherine Slip']), 'Broadway': set(['Broadway']), 'Row': set(['Park Row'])})\n"
     ]
    }
   ],
   "source": [
    "# Print all the steet types and names\n",
    "# We should be able to identify all problem steet names\n",
    "pprint.pprint(street_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fix these street names (wrong name: correct name)\n",
    "mapping = { \"AVENUE\": \"Avenue\",\n",
    "            \"AVenue\": \"Avenue\",\n",
    "            \"Ave\": \"Avenue\",\n",
    "            \"Ave.\": \"Avenue\",\n",
    "            \"Avene\": \"Avenue\",\n",
    "            \"Blvd\": \"Boulevard\",\n",
    "            \"Ct\": \"Court\",\n",
    "            \"DRIVE\": \"Drive\",\n",
    "            \"Dr\": \"Drive\",\n",
    "            \"Pkwy\": \"Parkway\",\n",
    "            \"Plz\": \"Plaza\",\n",
    "            \"ROAD\": \"Road\",\n",
    "            \"Rd\": \"Road\",\n",
    "            \"STREET\": \"Street\",            \n",
    "            \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"Steet\": \"Street\",\n",
    "            \"Trce\": \"Terrace\",\n",
    "            \"Tpke\": \"Turnpike\",\n",
    "            \"avenue\": \"Avenue\",\n",
    "            \"street\": \"Street\"\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_name(name, mapping):\n",
    "    m = street_type_re.search(name)\n",
    "    better_name = name\n",
    "    # condition: if the street name does have a last word\n",
    "    if m:\n",
    "        # check if the street type is a key in your mapping dictionary:\n",
    "        if m.group() in mapping.keys():\n",
    "            better_street_type = mapping[m.group()]\n",
    "            better_name = street_type_re.sub(better_street_type, name)\n",
    "    return better_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Henry Hudson Parkway West => Henry Hudson Parkway West\n",
      "Ilyssa Way => Ilyssa Way\n",
      "Covington Circle => Covington Circle\n",
      "Van Cortlandt Avenue East => Van Cortlandt Avenue East\n",
      "Kings Highway => Kings Highway\n",
      "New Highway => New Highway\n",
      "Grand Central Parkway Sr North => Grand Central Parkway Sr North\n",
      "Horace Harding Expressway Service Road North => Horace Harding Expressway Service Road North\n",
      "Harding Park => Harding Park\n",
      "Leewood Loop => Leewood Loop\n",
      "Hart Loop => Hart Loop\n",
      "Carlls Path => Carlls Path\n",
      "Carlls Straight Path => Carlls Straight Path\n",
      "Avenue A => Avenue A\n",
      "Avenue B => Avenue B\n",
      "Avenue I => Avenue I\n",
      "Avenue H => Avenue H\n",
      "Avenue K => Avenue K\n",
      "Avenue J => Avenue J\n",
      "Avenue L => Avenue L\n",
      "Avenue P => Avenue P\n",
      "Dover Green => Dover Green\n",
      "Avenue T => Avenue T\n",
      "Somerset Road W => Somerset Road W\n",
      "Union Turnpike => Union Turnpike\n",
      "Hempstead Turnpike => Hempstead Turnpike\n",
      "Avenue Z => Avenue Z\n",
      "Juniper Boulevard South => Juniper Boulevard South\n",
      "Winnecomac Cir => Winnecomac Cir\n",
      "John Golden Ballfields => John Golden Ballfields\n",
      "Susan Terrace => Susan Terrace\n",
      "Catherine Slip => Catherine Slip\n",
      "Broadway => Broadway\n",
      "Park Row => Park Row\n"
     ]
    }
   ],
   "source": [
    "# Fix the street names\n",
    "for st_type, ways in street_types.items():\n",
    "        for name in ways:\n",
    "            better_name = update_name(name, mapping)\n",
    "            print name, \"=>\", better_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import codecs\n",
    "import cerberus\n",
    "import schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# File path\n",
    "OSM_PATH = \"newyork_sample.osm\"\n",
    "\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LOWER_COLON = re.compile(r'^([a-zA-Z0-9]|_)+:([a-zA-Z0-9]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "SCHEMA = schema.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make sure the fields order in the csvs matches the column order in the sql table schema\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ================================================== #\n",
    "#               Helper Functions                     #\n",
    "# ================================================== #\n",
    "\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, default_tag_type='regular'):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []  # Handle secondary tags the same way for both node and way elements\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    if element.tag == 'node':\n",
    "        for i in node_attr_fields:\n",
    "            node_attribs[i] = element.attrib[i]\n",
    "            \n",
    "    if element.tag == 'way':\n",
    "        for i in way_attr_fields:\n",
    "            way_attribs[i] =element.attrib[i]\n",
    "            \n",
    "    for tag in element.iter('tag'):\n",
    "        dic = {}\n",
    "        \n",
    "        if problem_chars.search(tag.attrib['k']):\n",
    "            continue\n",
    "        \n",
    "        if element.tag == 'node':\n",
    "            dic['id'] = node_attribs['id']\n",
    "        elif element.tag == 'way':\n",
    "            dic['id'] = way_attribs['id']\n",
    "            \n",
    "        dic['value'] = tag.attrib['v']\n",
    "        \n",
    "        if LOWER_COLON.search(tag.attrib['k']):\n",
    "            dic['type'] = re.search('[a-zA-Z0-9]*:', tag.attrib['k']).group()[:-1] \n",
    "            dic['key'] = re.search(':([a-zA-Z0-9]|_)+:?([a-zA-Z0-9]|_)*$', tag.attrib['k']).group()[1:]\n",
    "        else:\n",
    "            dic['key'] = tag.attrib['k']\n",
    "            dic['type'] = 'regular'\n",
    "\n",
    "        tags.append(dic)\n",
    "\n",
    "    if element.tag == 'way':\n",
    "        count = 0 \n",
    "    \n",
    "        for nd in element.iter('nd'):\n",
    "            way_node_dict = {}\n",
    "            way_node_dict['id'] = way_attribs['id']\n",
    "            way_node_dict['node_id'] = nd.attrib['ref']\n",
    "            way_node_dict['position'] = count\n",
    "            count += 1\n",
    "        \n",
    "            way_nodes.append(way_node_dict)     \n",
    "        \n",
    "    if element.tag == 'node':   \n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "    elif element.tag == 'way':\n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "            \n",
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_string = pprint.pformat(errors)\n",
    "        \n",
    "        raise Exception(message_string.format(field, error_string))\n",
    "        \n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.items()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ================================================== #\n",
    "#               Main Function                        #\n",
    "# ================================================== #\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "         codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        validator = cerberus.Validator()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "process_map(OSM_PATH, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clear_empty(filenames):\n",
    "    for filename in filenames:\n",
    "        input = open(filename, 'rb')\n",
    "        output = open(filename[:-4]+'_noempty.csv', 'wb')\n",
    "        writer = csv.writer(output)\n",
    "        for row in csv.reader(input):\n",
    "            if any(row):\n",
    "                writer.writerow(row)\n",
    "        input.close()\n",
    "        output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filenames = glob.glob(\"*.csv\")\n",
    "clear_empty(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
